{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 任务三：基于注意力机制的文本匹配"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.数据加载和预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from torchtext.vocab import GloVe\n",
    "import collections\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import torchtext.vocab as Vocab\n",
    "import torch.utils.data as Data\n",
    "from tqdm import tqdm\n",
    "\n",
    "from nltk import word_tokenize\n",
    "import numpy as np\n",
    "\n",
    "class SNLI():\n",
    "    def __init__(self,batch_size,device):\n",
    "        start_time=time.time()\n",
    "        #定义如何处理数据和标签\n",
    "        print('1定义如何处理文本和标签')\n",
    "        self.TEXT=data.Field(batch_first=True,include_lengths=True,tokenize=word_tokenize,lower=True)\n",
    "        self.LABEL=data.Field(sequential=False,unk_token=None)\n",
    "        step1_time=time.time()\n",
    "        print('\\t耗时%.4f s'%(step1_time-start_time))\n",
    "      \n",
    "        #划分数据集\n",
    "        print('2划分数据集')\n",
    "        self.train,self.dev,self.test=datasets.SNLI.splits(self.TEXT,self.LABEL)\n",
    "        step2_time=time.time()\n",
    "        print('\\t耗时%.4f s'%(step2_time-step1_time))\n",
    "        \n",
    "        #创建词汇表\n",
    "        print('3创建词汇表')\n",
    "        self.TEXT.build_vocab(self.train,self.dev,self.test,vectors=GloVe(name='840B',dim=300))\n",
    "        self.LABEL.build_vocab(self.train)\n",
    "        step3_time=time.time()\n",
    "        print('\\t耗时%.4f s'%(step3_time-step2_time))\n",
    "        \n",
    "        #生成batch迭代器\n",
    "        print('4生成batch迭代器')\n",
    "        self.train_iter,self.dev_iter,self.test_iter=data.BucketIterator.splits((self.train,self.dev,self.test),\n",
    "                                                                                batch_size=batch_size,device=device)\n",
    "        step4_time=time.time()\n",
    "        print('\\t耗时%.4f s'%(step4_time-step3_time))\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1定义如何处理文本和标签\n",
      "\t耗时0.0000 s\n",
      "2划分数据集\n",
      "\t耗时152.3050 s\n",
      "3创建词汇表\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████▉| 2196016/2196017 [05:17<00:00, 6915.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t耗时412.5948 s\n",
      "4生成batch迭代器\n",
      "\t耗时0.0020 s\n"
     ]
    }
   ],
   "source": [
    "batch_size=32\n",
    "snli=SNLI(batch_size,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter,dev_iter,test_iter,vocab=snli.train_iter,snli.dev_iter,snli.test_iter,snli.TEXT.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "观察几个训练batch可以看到，每个batch中样本长度不同，因为是动态填充，每个batch都以最长的样本为基准Padding [1]到同样的长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[torchtext.data.batch.Batch of size 32 from SNLI]\n",
      "\t[.premise]:('[torch.cuda.LongTensor of size 32x36 (GPU 0)]', '[torch.cuda.LongTensor of size 32 (GPU 0)]')\n",
      "\t[.hypothesis]:('[torch.cuda.LongTensor of size 32x14 (GPU 0)]', '[torch.cuda.LongTensor of size 32 (GPU 0)]')\n",
      "\t[.label]:[torch.cuda.LongTensor of size 32 (GPU 0)]\n",
      "(tensor([[   2,  283,    7,  ...,    1,    1,    1],\n",
      "        [   2, 1334,   13,  ...,    1,    1,    1],\n",
      "        [  58,   15,   10,  ...,    1,    1,    1],\n",
      "        ...,\n",
      "        [   2,   31,    6,  ...,    1,    1,    1],\n",
      "        [   2,   43,    5,  ...,    1,    1,    1],\n",
      "        [   2,  299,   12,  ...,    1,    1,    1]], device='cuda:0'), tensor([ 8, 19,  8, 12, 11, 15, 14, 36, 11,  6,  8, 18, 10, 23, 16, 16, 10, 21,\n",
      "         8, 14, 12, 22, 11, 19, 11, 12, 23, 11, 12, 15, 13, 18],\n",
      "       device='cuda:0')) tensor([1, 1, 0, 0, 0, 0, 0, 2, 2, 2, 1, 0, 2, 0, 0, 2, 2, 0, 2, 0, 2, 0, 1, 1,\n",
      "        0, 2, 0, 2, 0, 1, 2, 1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for i,x in enumerate(train_iter):\n",
    "    print(x)\n",
    "    print(x.premise,x.label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x0000020DE12DA888>>,\n",
       "            {'<unk>': 0,\n",
       "             '<pad>': 1,\n",
       "             'a': 2,\n",
       "             '.': 3,\n",
       "             'the': 4,\n",
       "             'in': 5,\n",
       "             'is': 6,\n",
       "             'man': 7,\n",
       "             'on': 8,\n",
       "             'and': 9,\n",
       "             'are': 10,\n",
       "             'of': 11,\n",
       "             'with': 12,\n",
       "             'woman': 13,\n",
       "             'two': 14,\n",
       "             'people': 15,\n",
       "             ',': 16,\n",
       "             'to': 17,\n",
       "             'at': 18,\n",
       "             'wearing': 19,\n",
       "             'an': 20,\n",
       "             'his': 21,\n",
       "             'young': 22,\n",
       "             'men': 23,\n",
       "             'playing': 24,\n",
       "             'girl': 25,\n",
       "             'boy': 26,\n",
       "             'white': 27,\n",
       "             'shirt': 28,\n",
       "             'while': 29,\n",
       "             'black': 30,\n",
       "             'dog': 31,\n",
       "             'sitting': 32,\n",
       "             'blue': 33,\n",
       "             'standing': 34,\n",
       "             'her': 35,\n",
       "             'red': 36,\n",
       "             'group': 37,\n",
       "             'for': 38,\n",
       "             'down': 39,\n",
       "             'walking': 40,\n",
       "             'outside': 41,\n",
       "             'street': 42,\n",
       "             'person': 43,\n",
       "             'front': 44,\n",
       "             'women': 45,\n",
       "             'holding': 46,\n",
       "             'child': 47,\n",
       "             'one': 48,\n",
       "             'by': 49,\n",
       "             'three': 50,\n",
       "             'there': 51,\n",
       "             'water': 52,\n",
       "             'their': 53,\n",
       "             'up': 54,\n",
       "             'children': 55,\n",
       "             'looking': 56,\n",
       "             'as': 57,\n",
       "             'some': 58,\n",
       "             'green': 59,\n",
       "             'from': 60,\n",
       "             'little': 61,\n",
       "             'other': 62,\n",
       "             'large': 63,\n",
       "             'through': 64,\n",
       "             'has': 65,\n",
       "             'running': 66,\n",
       "             'yellow': 67,\n",
       "             'riding': 68,\n",
       "             'ball': 69,\n",
       "             'out': 70,\n",
       "             'hat': 71,\n",
       "             'next': 72,\n",
       "             'into': 73,\n",
       "             'brown': 74,\n",
       "             'building': 75,\n",
       "             'near': 76,\n",
       "             'beach': 77,\n",
       "             'dressed': 78,\n",
       "             'over': 79,\n",
       "             'small': 80,\n",
       "             'girls': 81,\n",
       "             'another': 82,\n",
       "             'dogs': 83,\n",
       "             'around': 84,\n",
       "             'crowd': 85,\n",
       "             \"'s\": 86,\n",
       "             'bike': 87,\n",
       "             'jacket': 88,\n",
       "             'field': 89,\n",
       "             'stands': 90,\n",
       "             'sits': 91,\n",
       "             'it': 92,\n",
       "             'table': 93,\n",
       "             'jumping': 94,\n",
       "             'working': 95,\n",
       "             'that': 96,\n",
       "             'behind': 97,\n",
       "             'park': 98,\n",
       "             'orange': 99,\n",
       "             'sidewalk': 100,\n",
       "             'background': 101,\n",
       "             'boys': 102,\n",
       "             'car': 103,\n",
       "             'lady': 104,\n",
       "             'pink': 105,\n",
       "             'picture': 106,\n",
       "             'looks': 107,\n",
       "             'player': 108,\n",
       "             'game': 109,\n",
       "             'talking': 110,\n",
       "             'snow': 111,\n",
       "             'watching': 112,\n",
       "             'something': 113,\n",
       "             'play': 114,\n",
       "             'grass': 115,\n",
       "             'hair': 116,\n",
       "             'top': 117,\n",
       "             'together': 118,\n",
       "             'off': 119,\n",
       "             'plays': 120,\n",
       "             'camera': 121,\n",
       "             'four': 122,\n",
       "             'old': 123,\n",
       "             'couple': 124,\n",
       "             'eating': 125,\n",
       "             'soccer': 126,\n",
       "             'wall': 127,\n",
       "             'stand': 128,\n",
       "             'city': 129,\n",
       "             'taking': 130,\n",
       "             'kids': 131,\n",
       "             'asian': 132,\n",
       "             'he': 133,\n",
       "             'they': 134,\n",
       "             'air': 135,\n",
       "             'dress': 136,\n",
       "             'food': 137,\n",
       "             'walks': 138,\n",
       "             'older': 139,\n",
       "             'him': 140,\n",
       "             'shorts': 141,\n",
       "             'several': 142,\n",
       "             'guitar': 143,\n",
       "             'baby': 144,\n",
       "             'being': 145,\n",
       "             'pants': 146,\n",
       "             'guy': 147,\n",
       "             'each': 148,\n",
       "             'bench': 149,\n",
       "             'doing': 150,\n",
       "             'sleeping': 151,\n",
       "             'gray': 152,\n",
       "             'walk': 153,\n",
       "             'outdoors': 154,\n",
       "             'road': 155,\n",
       "             'holds': 156,\n",
       "             'pool': 157,\n",
       "             'hand': 158,\n",
       "             'jeans': 159,\n",
       "             'inside': 160,\n",
       "             'waiting': 161,\n",
       "             'smiling': 162,\n",
       "             'carrying': 163,\n",
       "             'them': 164,\n",
       "             'sit': 165,\n",
       "             'baseball': 166,\n",
       "             'tree': 167,\n",
       "             'along': 168,\n",
       "             'about': 169,\n",
       "             'hands': 170,\n",
       "             'boat': 171,\n",
       "             'performing': 172,\n",
       "             'day': 173,\n",
       "             'swimming': 174,\n",
       "             'stage': 175,\n",
       "             'ground': 176,\n",
       "             'who': 177,\n",
       "             'back': 178,\n",
       "             'getting': 179,\n",
       "             'room': 180,\n",
       "             'race': 181,\n",
       "             'head': 182,\n",
       "             'someone': 183,\n",
       "             'face': 184,\n",
       "             'side': 185,\n",
       "             'having': 186,\n",
       "             'female': 187,\n",
       "             'work': 188,\n",
       "             'football': 189,\n",
       "             'all': 190,\n",
       "             'construction': 191,\n",
       "             'rock': 192,\n",
       "             'band': 193,\n",
       "             'male': 194,\n",
       "             'glasses': 195,\n",
       "             'horse': 196,\n",
       "             'bicycle': 197,\n",
       "             'trying': 198,\n",
       "             'store': 199,\n",
       "             'workers': 200,\n",
       "             'reading': 201,\n",
       "             'dancing': 202,\n",
       "             'blond': 203,\n",
       "             'using': 204,\n",
       "             'jumps': 205,\n",
       "             'be': 206,\n",
       "             'making': 207,\n",
       "             'look': 208,\n",
       "             'sign': 209,\n",
       "             'players': 210,\n",
       "             'dark': 211,\n",
       "             'going': 212,\n",
       "             'dirt': 213,\n",
       "             'area': 214,\n",
       "             'she': 215,\n",
       "             'long': 216,\n",
       "             'this': 217,\n",
       "             'ocean': 218,\n",
       "             'train': 219,\n",
       "             'suit': 220,\n",
       "             'tennis': 221,\n",
       "             't-shirt': 222,\n",
       "             'many': 223,\n",
       "             'basketball': 224,\n",
       "             'team': 225,\n",
       "             'sand': 226,\n",
       "             'under': 227,\n",
       "             'watch': 228,\n",
       "             'coat': 229,\n",
       "             'runs': 230,\n",
       "             'across': 231,\n",
       "             'rides': 232,\n",
       "             'mountain': 233,\n",
       "             'climbing': 234,\n",
       "             'sunglasses': 235,\n",
       "             'was': 236,\n",
       "             'home': 237,\n",
       "             'restaurant': 238,\n",
       "             'toy': 239,\n",
       "             'floor': 240,\n",
       "             'chair': 241,\n",
       "             'watches': 242,\n",
       "             'its': 243,\n",
       "             'purple': 244,\n",
       "             'mouth': 245,\n",
       "             'striped': 246,\n",
       "             'window': 247,\n",
       "             'friends': 248,\n",
       "             'during': 249,\n",
       "             'kid': 250,\n",
       "             'have': 251,\n",
       "             'music': 252,\n",
       "             'bus': 253,\n",
       "             'family': 254,\n",
       "             'uniform': 255,\n",
       "             'helmet': 256,\n",
       "             'after': 257,\n",
       "             'lake': 258,\n",
       "             'or': 259,\n",
       "             'ready': 260,\n",
       "             'clothing': 261,\n",
       "             'ride': 262,\n",
       "             'microphone': 263,\n",
       "             'elderly': 264,\n",
       "             'not': 265,\n",
       "             'house': 266,\n",
       "             'singing': 267,\n",
       "             'truck': 268,\n",
       "             'against': 269,\n",
       "             'clothes': 270,\n",
       "             'posing': 271,\n",
       "             'bag': 272,\n",
       "             'skateboard': 273,\n",
       "             'trees': 274,\n",
       "             'drinking': 275,\n",
       "             'laying': 276,\n",
       "             'very': 277,\n",
       "             'ice': 278,\n",
       "             'enjoying': 279,\n",
       "             'middle': 280,\n",
       "             'no': 281,\n",
       "             'shopping': 282,\n",
       "             'big': 283,\n",
       "             'wooden': 284,\n",
       "             'line': 285,\n",
       "             'busy': 286,\n",
       "             'past': 287,\n",
       "             'shirts': 288,\n",
       "             'kitchen': 289,\n",
       "             'book': 290,\n",
       "             'cap': 291,\n",
       "             'motorcycle': 292,\n",
       "             'guys': 293,\n",
       "             'worker': 294,\n",
       "             'outdoor': 295,\n",
       "             'away': 296,\n",
       "             'light': 297,\n",
       "             'five': 298,\n",
       "             'market': 299,\n",
       "             'fence': 300,\n",
       "             'river': 301,\n",
       "             '``': 302,\n",
       "             \"''\": 303,\n",
       "             'get': 304,\n",
       "             'couch': 305,\n",
       "             'towards': 306,\n",
       "             'painting': 307,\n",
       "             'colorful': 308,\n",
       "             'hats': 309,\n",
       "             'phone': 310,\n",
       "             'tall': 311,\n",
       "             'takes': 312,\n",
       "             'hill': 313,\n",
       "             'bed': 314,\n",
       "             'others': 315,\n",
       "             'jump': 316,\n",
       "             'driving': 317,\n",
       "             'high': 318,\n",
       "             'open': 319,\n",
       "             'just': 320,\n",
       "             'event': 321,\n",
       "             'sweater': 322,\n",
       "             'beside': 323,\n",
       "             'covered': 324,\n",
       "             'cart': 325,\n",
       "             'arms': 326,\n",
       "             'cat': 327,\n",
       "             'fire': 328,\n",
       "             'photo': 329,\n",
       "             'track': 330,\n",
       "             'stick': 331,\n",
       "             'party': 332,\n",
       "             'tan': 333,\n",
       "             'night': 334,\n",
       "             'path': 335,\n",
       "             'school': 336,\n",
       "             'bright': 337,\n",
       "             'piece': 338,\n",
       "             'swing': 339,\n",
       "             'mother': 340,\n",
       "             'does': 341,\n",
       "             'fishing': 342,\n",
       "             'bar': 343,\n",
       "             'toddler': 344,\n",
       "             'cooking': 345,\n",
       "             'dance': 346,\n",
       "             'catch': 347,\n",
       "             'like': 348,\n",
       "             'preparing': 349,\n",
       "             'run': 350,\n",
       "             'umbrella': 351,\n",
       "             'both': 352,\n",
       "             'vest': 353,\n",
       "             'new': 354,\n",
       "             'adults': 355,\n",
       "             'brick': 356,\n",
       "             'surrounded': 357,\n",
       "             'shoes': 358,\n",
       "             'trick': 359,\n",
       "             'body': 360,\n",
       "             'hockey': 361,\n",
       "             'colored': 362,\n",
       "             'shop': 363,\n",
       "             'cellphone': 364,\n",
       "             'full': 365,\n",
       "             'hard': 366,\n",
       "             'racing': 367,\n",
       "             'selling': 368,\n",
       "             'tank': 369,\n",
       "             'lot': 370,\n",
       "             'alone': 371,\n",
       "             'bridge': 372,\n",
       "             'paper': 373,\n",
       "             'hanging': 374,\n",
       "             'flowers': 375,\n",
       "             'rope': 376,\n",
       "             'board': 377,\n",
       "             'grassy': 378,\n",
       "             'outfit': 379,\n",
       "             'concert': 380,\n",
       "             'animal': 381,\n",
       "             'rocks': 382,\n",
       "             'bikes': 383,\n",
       "             'onto': 384,\n",
       "             'pictures': 385,\n",
       "             'police': 386,\n",
       "             'gathered': 387,\n",
       "             'stone': 388,\n",
       "             'sun': 389,\n",
       "             'uniforms': 390,\n",
       "             'take': 391,\n",
       "             'metal': 392,\n",
       "             'subway': 393,\n",
       "             'pole': 394,\n",
       "             'were': 395,\n",
       "             'right': 396,\n",
       "             'what': 397,\n",
       "             'fish': 398,\n",
       "             'left': 399,\n",
       "             'american': 400,\n",
       "             'asleep': 401,\n",
       "             'steps': 402,\n",
       "             'above': 403,\n",
       "             'set': 404,\n",
       "             'cowboy': 405,\n",
       "             'machine': 406,\n",
       "             'sunny': 407,\n",
       "             'drink': 408,\n",
       "             'which': 409,\n",
       "             'ladies': 410,\n",
       "             'costume': 411,\n",
       "             'laughing': 412,\n",
       "             'smiles': 413,\n",
       "             'time': 414,\n",
       "             'practicing': 415,\n",
       "             'snowy': 416,\n",
       "             'instrument': 417,\n",
       "             'flag': 418,\n",
       "             'frisbee': 419,\n",
       "             'pose': 420,\n",
       "             'skirt': 421,\n",
       "             'backpack': 422,\n",
       "             'stairs': 423,\n",
       "             'leaning': 424,\n",
       "             'crowded': 425,\n",
       "             'empty': 426,\n",
       "             'seated': 427,\n",
       "             'instruments': 428,\n",
       "             'dinner': 429,\n",
       "             'shirtless': 430,\n",
       "             'throwing': 431,\n",
       "             'go': 432,\n",
       "             'putting': 433,\n",
       "             'volleyball': 434,\n",
       "             'parade': 435,\n",
       "             'arm': 436,\n",
       "             'show': 437,\n",
       "             'rain': 438,\n",
       "             'can': 439,\n",
       "             'fountain': 440,\n",
       "             'cleaning': 441,\n",
       "             'competition': 442,\n",
       "             'sky': 443,\n",
       "             'computer': 444,\n",
       "             'vehicle': 445,\n",
       "             'cars': 446,\n",
       "             'skateboarder': 447,\n",
       "             'audience': 448,\n",
       "             'forest': 449,\n",
       "             'african': 450,\n",
       "             'gear': 451,\n",
       "             'wood': 452,\n",
       "             'between': 453,\n",
       "             'horses': 454,\n",
       "             'performs': 455,\n",
       "             'beer': 456,\n",
       "             'glass': 457,\n",
       "             'adult': 458,\n",
       "             'wave': 459,\n",
       "             'chairs': 460,\n",
       "             'human': 461,\n",
       "             'corner': 462,\n",
       "             'equipment': 463,\n",
       "             'public': 464,\n",
       "             'nobody': 465,\n",
       "             'break': 466,\n",
       "             'indoors': 467,\n",
       "             'woods': 468,\n",
       "             'slide': 469,\n",
       "             'giving': 470,\n",
       "             'smoking': 471,\n",
       "             'son': 472,\n",
       "             'chasing': 473,\n",
       "             'father': 474,\n",
       "             '2': 475,\n",
       "             'students': 476,\n",
       "             'object': 477,\n",
       "             'number': 478,\n",
       "             'setting': 479,\n",
       "             'door': 480,\n",
       "             'art': 481,\n",
       "             'before': 482,\n",
       "             'appears': 483,\n",
       "             'wedding': 484,\n",
       "             'wet': 485,\n",
       "             'rider': 486,\n",
       "             'cream': 487,\n",
       "             'friend': 488,\n",
       "             'make': 489,\n",
       "             'bags': 490,\n",
       "             'pushing': 491,\n",
       "             'nearby': 492,\n",
       "             'works': 493,\n",
       "             'bird': 494,\n",
       "             'eyes': 495,\n",
       "             'short': 496,\n",
       "             'hot': 497,\n",
       "             'poses': 498,\n",
       "             'winter': 499,\n",
       "             'happy': 500,\n",
       "             'concrete': 501,\n",
       "             'view': 502,\n",
       "             'yard': 503,\n",
       "             'roof': 504,\n",
       "             'toward': 505,\n",
       "             'playground': 506,\n",
       "             'beard': 507,\n",
       "             'flying': 508,\n",
       "             'coffee': 509,\n",
       "             'lunch': 510,\n",
       "             'fighting': 511,\n",
       "             'where': 512,\n",
       "             'few': 513,\n",
       "             'showing': 514,\n",
       "             'listening': 515,\n",
       "             'beautiful': 516,\n",
       "             'wears': 517,\n",
       "             'swim': 518,\n",
       "             'fruit': 519,\n",
       "             'boots': 520,\n",
       "             'sports': 521,\n",
       "             'bowling': 522,\n",
       "             'fun': 523,\n",
       "             'scarf': 524,\n",
       "             'lying': 525,\n",
       "             'plaid': 526,\n",
       "             'plastic': 527,\n",
       "             'statue': 528,\n",
       "             'way': 529,\n",
       "             'mountains': 530,\n",
       "             'drinks': 531,\n",
       "             'cutting': 532,\n",
       "             'painted': 533,\n",
       "             'station': 534,\n",
       "             'sweatshirt': 535,\n",
       "             'biker': 536,\n",
       "             'leaves': 537,\n",
       "             'ramp': 538,\n",
       "             'same': 539,\n",
       "             'tv': 540,\n",
       "             'pulling': 541,\n",
       "             'distance': 542,\n",
       "             'graffiti': 543,\n",
       "             'trail': 544,\n",
       "             'makes': 545,\n",
       "             'animals': 546,\n",
       "             'crossing': 547,\n",
       "             'bunch': 548,\n",
       "             'eat': 549,\n",
       "             'snowboarder': 550,\n",
       "             'feet': 551,\n",
       "             'martial': 552,\n",
       "             'cake': 553,\n",
       "             'cigarette': 554,\n",
       "             'do': 555,\n",
       "             'lawn': 556,\n",
       "             'buildings': 557,\n",
       "             'eats': 558,\n",
       "             'perform': 559,\n",
       "             'surfer': 560,\n",
       "             'skateboarding': 561,\n",
       "             'drums': 562,\n",
       "             'class': 563,\n",
       "             'box': 564,\n",
       "             'cross': 565,\n",
       "             'different': 566,\n",
       "             'gets': 567,\n",
       "             'match': 568,\n",
       "             'reads': 569,\n",
       "             'teams': 570,\n",
       "             'gentleman': 571,\n",
       "             'jersey': 572,\n",
       "             'competing': 573,\n",
       "             'ladder': 574,\n",
       "             'talk': 575,\n",
       "             'edge': 576,\n",
       "             'safety': 577,\n",
       "             'prepares': 578,\n",
       "             'cup': 579,\n",
       "             'parked': 580,\n",
       "             'six': 581,\n",
       "             'made': 582,\n",
       "             'hit': 583,\n",
       "             'filled': 584,\n",
       "             'place': 585,\n",
       "             'how': 586,\n",
       "             'talks': 587,\n",
       "             'business': 588,\n",
       "             'video': 589,\n",
       "             'arts': 590,\n",
       "             'parking': 591,\n",
       "             'court': 592,\n",
       "             'stop': 593,\n",
       "             'suits': 594,\n",
       "             'moving': 595,\n",
       "             'hold': 596,\n",
       "             'tent': 597,\n",
       "             'carries': 598,\n",
       "             'rodeo': 599,\n",
       "             'church': 600,\n",
       "             'bottle': 601,\n",
       "             'gloves': 602,\n",
       "             'paint': 603,\n",
       "             'shore': 604,\n",
       "             'desk': 605,\n",
       "             'first': 606,\n",
       "             'newspaper': 607,\n",
       "             'items': 608,\n",
       "             'bathing': 609,\n",
       "             'daughter': 610,\n",
       "             'midair': 611,\n",
       "             'bald': 612,\n",
       "             'apron': 613,\n",
       "             'resting': 614,\n",
       "             'bull': 615,\n",
       "             'scene': 616,\n",
       "             'speaking': 617,\n",
       "             'swinging': 618,\n",
       "             'vendor': 619,\n",
       "             'costumes': 620,\n",
       "             'display': 621,\n",
       "             'only': 622,\n",
       "             'office': 623,\n",
       "             'taken': 624,\n",
       "             'tries': 625,\n",
       "             'waits': 626,\n",
       "             '3': 627,\n",
       "             \"n't\": 628,\n",
       "             'rocky': 629,\n",
       "             'staring': 630,\n",
       "             'jackets': 631,\n",
       "             'pointing': 632,\n",
       "             'net': 633,\n",
       "             'cafe': 634,\n",
       "             'crying': 635,\n",
       "             'marathon': 636,\n",
       "             'surfing': 637,\n",
       "             'spectators': 638,\n",
       "             'because': 639,\n",
       "             'musicians': 640,\n",
       "             'see': 641,\n",
       "             'skier': 642,\n",
       "             'life': 643,\n",
       "             'wait': 644,\n",
       "             'clown': 645,\n",
       "             'balloon': 646,\n",
       "             'bucket': 647,\n",
       "             'skiing': 648,\n",
       "             'shoulder': 649,\n",
       "             'writing': 650,\n",
       "             'grill': 651,\n",
       "             'golf': 652,\n",
       "             'tricks': 653,\n",
       "             'structure': 654,\n",
       "             'gold': 655,\n",
       "             'legs': 656,\n",
       "             'facing': 657,\n",
       "             'traffic': 658,\n",
       "             'smile': 659,\n",
       "             'himself': 660,\n",
       "             'waves': 661,\n",
       "             'younger': 662,\n",
       "             'cliff': 663,\n",
       "             'artist': 664,\n",
       "             'pile': 665,\n",
       "             'basket': 666,\n",
       "             'gym': 667,\n",
       "             'meal': 668,\n",
       "             'humans': 669,\n",
       "             'kicking': 670,\n",
       "             'foreground': 671,\n",
       "             'counter': 672,\n",
       "             'dock': 673,\n",
       "             'fixing': 674,\n",
       "             'flags': 675,\n",
       "             'musical': 676,\n",
       "             'bowl': 677,\n",
       "             'hiking': 678,\n",
       "             'dresses': 679,\n",
       "             'bride': 680,\n",
       "             'conversation': 681,\n",
       "             'onlookers': 682,\n",
       "             'blanket': 683,\n",
       "             'shot': 684,\n",
       "             'desert': 685,\n",
       "             'goggles': 686,\n",
       "             'site': 687,\n",
       "             'leans': 688,\n",
       "             'helping': 689,\n",
       "             'vests': 690,\n",
       "             'military': 691,\n",
       "             'mask': 692,\n",
       "             'middle-aged': 693,\n",
       "             'various': 694,\n",
       "             'indian': 695,\n",
       "             'christmas': 696,\n",
       "             'tie': 697,\n",
       "             'climbs': 698,\n",
       "             'blond-hair': 699,\n",
       "             'diving': 700,\n",
       "             'flower': 701,\n",
       "             'sad': 702,\n",
       "             'garden': 703,\n",
       "             'karate': 704,\n",
       "             'sleeps': 705,\n",
       "             'bicycles': 706,\n",
       "             'classroom': 707,\n",
       "             'uses': 708,\n",
       "             'purse': 709,\n",
       "             'cold': 710,\n",
       "             'sings': 711,\n",
       "             'skating': 712,\n",
       "             'held': 713,\n",
       "             'picnic': 714,\n",
       "             'streets': 715,\n",
       "             'scooter': 716,\n",
       "             'bikini': 717,\n",
       "             'attempting': 718,\n",
       "             'stroller': 719,\n",
       "             'musician': 720,\n",
       "             'vegetables': 721,\n",
       "             'town': 722,\n",
       "             'alley': 723,\n",
       "             'owner': 724,\n",
       "             'throws': 725,\n",
       "             'country': 726,\n",
       "             'chinese': 727,\n",
       "             'huge': 728,\n",
       "             'leather': 729,\n",
       "             'these': 730,\n",
       "             'signs': 731,\n",
       "             'toys': 732,\n",
       "             'attire': 733,\n",
       "             'gather': 734,\n",
       "             'fight': 735,\n",
       "             'officer': 736,\n",
       "             'photographer': 737,\n",
       "             'jogging': 738,\n",
       "             'ski': 739,\n",
       "             'stadium': 740,\n",
       "             'performance': 741,\n",
       "             'shows': 742,\n",
       "             'plane': 743,\n",
       "             'railing': 744,\n",
       "             'living': 745,\n",
       "             'washing': 746,\n",
       "             'waving': 747,\n",
       "             'naked': 748,\n",
       "             'throw': 749,\n",
       "             'dancers': 750,\n",
       "             'blowing': 751,\n",
       "             'goes': 752,\n",
       "             'part': 753,\n",
       "             'cement': 754,\n",
       "             'violin': 755,\n",
       "             'sort': 756,\n",
       "             'money': 757,\n",
       "             'males': 758,\n",
       "             'enjoy': 759,\n",
       "             'relaxing': 760,\n",
       "             'birthday': 761,\n",
       "             'laptop': 762,\n",
       "             'gathering': 763,\n",
       "             'kissing': 764,\n",
       "             'wife': 765,\n",
       "             'performer': 766,\n",
       "             'close': 767,\n",
       "             'seen': 768,\n",
       "             'nap': 769,\n",
       "             'professional': 770,\n",
       "             'movie': 771,\n",
       "             'brunette': 772,\n",
       "             'singer': 773,\n",
       "             'foot': 774,\n",
       "             'bearded': 775,\n",
       "             'screen': 776,\n",
       "             'faces': 777,\n",
       "             'platform': 778,\n",
       "             'local': 779,\n",
       "             'sunset': 780,\n",
       "             'coming': 781,\n",
       "             'bubbles': 782,\n",
       "             'meat': 783,\n",
       "             'tables': 784,\n",
       "             'well': 785,\n",
       "             'balloons': 786,\n",
       "             'chef': 787,\n",
       "             'dark-haired': 788,\n",
       "             'lined': 789,\n",
       "             'surfboard': 790,\n",
       "             'lap': 791,\n",
       "             'airplane': 792,\n",
       "             'course': 793,\n",
       "             'trampoline': 794,\n",
       "             'says': 795,\n",
       "             'plate': 796,\n",
       "             'leg': 797,\n",
       "             'helmets': 798,\n",
       "             'hole': 799,\n",
       "             'silver': 800,\n",
       "             'swings': 801,\n",
       "             'festival': 802,\n",
       "             'windows': 803,\n",
       "             'good': 804,\n",
       "             'rail': 805,\n",
       "             'grocery': 806,\n",
       "             'mall': 807,\n",
       "             'mud': 808,\n",
       "             'digging': 809,\n",
       "             'outfits': 810,\n",
       "             'females': 811,\n",
       "             'goal': 812,\n",
       "             'mirror': 813,\n",
       "             'picking': 814,\n",
       "             'ledge': 815,\n",
       "             'members': 816,\n",
       "             'roller': 817,\n",
       "             'closed': 818,\n",
       "             'leaps': 819,\n",
       "             'puppy': 820,\n",
       "             'wear': 821,\n",
       "             'so': 822,\n",
       "             'trunks': 823,\n",
       "             'headphones': 824,\n",
       "             'kick': 825,\n",
       "             'dirty': 826,\n",
       "             'lit': 827,\n",
       "             'fair': 828,\n",
       "             'pass': 829,\n",
       "             'lights': 830,\n",
       "             'pond': 831,\n",
       "             'sliding': 832,\n",
       "             'base': 833,\n",
       "             'cyclist': 834,\n",
       "             'summer': 835,\n",
       "             'kneeling': 836,\n",
       "             'pair': 837,\n",
       "             'project': 838,\n",
       "             'tracks': 839,\n",
       "             'bat': 840,\n",
       "             'drawing': 841,\n",
       "             'runners': 842,\n",
       "             'climb': 843,\n",
       "             'makeup': 844,\n",
       "             'been': 845,\n",
       "             'giant': 846,\n",
       "             'trash': 847,\n",
       "             'overlooking': 848,\n",
       "             'buying': 849,\n",
       "             'drives': 850,\n",
       "             ';': 851,\n",
       "             'fast': 852,\n",
       "             'block': 853,\n",
       "             'shoulders': 854,\n",
       "             'sculpture': 855,\n",
       "             'lab': 856,\n",
       "             'electric': 857,\n",
       "             'piano': 858,\n",
       "             'games': 859,\n",
       "             'coats': 860,\n",
       "             'among': 861,\n",
       "             'but': 862,\n",
       "             'hugging': 863,\n",
       "             'passing': 864,\n",
       "             'sandals': 865,\n",
       "             'song': 866,\n",
       "             'married': 867,\n",
       "             \"'\": 868,\n",
       "             'clean': 869,\n",
       "             'homeless': 870,\n",
       "             'books': 871,\n",
       "             'wheel': 872,\n",
       "             'clear': 873,\n",
       "             'traditional': 874,\n",
       "             'teenagers': 875,\n",
       "             'put': 876,\n",
       "             'enjoys': 877,\n",
       "             'catching': 878,\n",
       "             'nose': 879,\n",
       "             'brightly': 880,\n",
       "             'teenage': 881,\n",
       "             'birds': 882,\n",
       "             'urban': 883,\n",
       "             'touching': 884,\n",
       "             'van': 885,\n",
       "             'had': 886,\n",
       "             'club': 887,\n",
       "             'drum': 888,\n",
       "             'seat': 889,\n",
       "             'nice': 890,\n",
       "             'things': 891,\n",
       "             'balls': 892,\n",
       "             'tattoo': 893,\n",
       "             'leash': 894,\n",
       "             'celebrating': 895,\n",
       "             'sled': 896,\n",
       "             'square': 897,\n",
       "             'canoe': 898,\n",
       "             'falling': 899,\n",
       "             'dances': 900,\n",
       "             'gun': 901,\n",
       "             'walkway': 902,\n",
       "             'sport': 903,\n",
       "             'dry': 904,\n",
       "             'booth': 905,\n",
       "             'plants': 906,\n",
       "             'help': 907,\n",
       "             'shovel': 908,\n",
       "             'parents': 909,\n",
       "             'sandy': 910,\n",
       "             'sticks': 911,\n",
       "             'individuals': 912,\n",
       "             'device': 913,\n",
       "             'telescope': 914,\n",
       "             'lays': 915,\n",
       "             'center': 916,\n",
       "             'cheerleaders': 917,\n",
       "             'tire': 918,\n",
       "             'turn': 919,\n",
       "             'backyard': 920,\n",
       "             'stream': 921,\n",
       "             'ring': 922,\n",
       "             'here': 923,\n",
       "             'sea': 924,\n",
       "             'below': 925,\n",
       "             'opposing': 926,\n",
       "             'attached': 927,\n",
       "             'mom': 928,\n",
       "             'upside': 929,\n",
       "             'collar': 930,\n",
       "             'will': 931,\n",
       "             'climber': 932,\n",
       "             'cut': 933,\n",
       "             'officers': 934,\n",
       "             'colors': 935,\n",
       "             'sale': 936,\n",
       "             'microscope': 937,\n",
       "             'also': 938,\n",
       "             'skate': 939,\n",
       "             'catches': 940,\n",
       "             'weather': 941,\n",
       "             'job': 942,\n",
       "             'wooded': 943,\n",
       "             'pier': 944,\n",
       "             'sweeping': 945,\n",
       "             'barefoot': 946,\n",
       "             'leaping': 947,\n",
       "             'meeting': 948,\n",
       "             'heads': 949,\n",
       "             'runner': 950,\n",
       "             'umbrellas': 951,\n",
       "             'museum': 952,\n",
       "             'marching': 953,\n",
       "             'circle': 954,\n",
       "             'pizza': 955,\n",
       "             'photograph': 956,\n",
       "             'fans': 957,\n",
       "             'heavy': 958,\n",
       "             'checking': 959,\n",
       "             'type': 960,\n",
       "             'tourists': 961,\n",
       "             'wine': 962,\n",
       "             'produce': 963,\n",
       "             'points': 964,\n",
       "             'teacher': 965,\n",
       "             'lots': 966,\n",
       "             'porch': 967,\n",
       "             'without': 968,\n",
       "             'sewing': 969,\n",
       "             'fall': 970,\n",
       "             'prepare': 971,\n",
       "             'chases': 972,\n",
       "             'flip': 973,\n",
       "             'cow': 974,\n",
       "             'candy': 975,\n",
       "             'doorway': 976,\n",
       "             'happily': 977,\n",
       "             'indoor': 978,\n",
       "             'kicks': 979,\n",
       "             'pushes': 980,\n",
       "             'carnival': 981,\n",
       "             'pulled': 982,\n",
       "             'shown': 983,\n",
       "             'move': 984,\n",
       "             'stuffed': 985,\n",
       "             'matching': 986,\n",
       "             'attempts': 987,\n",
       "             'laundry': 988,\n",
       "             'multiple': 989,\n",
       "             'bicyclist': 990,\n",
       "             'teeth': 991,\n",
       "             'gymnast': 992,\n",
       "             'pedestrians': 993,\n",
       "             'practice': 994,\n",
       "             'puts': 995,\n",
       "             'swims': 996,\n",
       "             'juggling': 997,\n",
       "             'garbage': 998,\n",
       "             'deck': 999,\n",
       "             ...})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1986, -0.0628, -0.3661, -0.4179,  0.2096, -0.2673,  0.2460,  0.1278,\n",
       "        -0.0458,  2.5253,  0.3520,  0.0935,  0.0866, -0.1193, -0.0624, -0.1926,\n",
       "        -0.1178,  1.4466, -0.5956, -0.0779, -0.3133, -0.1653,  0.0526, -0.1715,\n",
       "        -0.0731,  0.0559, -0.2939, -0.2025,  0.0781, -0.0800, -0.1561, -0.0657,\n",
       "        -0.0595, -0.0250,  0.1039,  0.2579, -0.2203, -0.0935, -0.0185, -0.0976,\n",
       "        -0.3875,  0.2554, -0.1344,  0.2989,  0.1525,  0.0373, -0.0316, -0.3345,\n",
       "         0.0897,  0.0314, -0.1805, -0.1350, -0.2551, -0.1749,  0.0691, -0.2049,\n",
       "        -0.0906, -0.0155, -0.2772,  0.1814,  0.1595, -0.2087, -0.2764,  0.3273,\n",
       "        -0.0573,  0.1798,  0.0128,  0.3842,  0.1590, -0.0144, -0.0375,  0.1903,\n",
       "         0.8313, -0.0500,  0.3258, -0.2754,  0.2384, -0.1607,  0.3132,  0.3932,\n",
       "        -0.0119,  0.1894, -0.6243, -0.1962,  0.0844, -0.3168, -0.1948,  0.0633,\n",
       "         0.2979,  0.0058, -0.1860, -0.0506,  0.2250, -0.0846,  0.2914,  0.1910,\n",
       "        -0.0775, -0.1179, -0.0850, -0.4056, -0.1679,  0.2649, -0.0924, -0.0632,\n",
       "         0.3363, -0.8922, -0.3509, -0.2051,  0.0162,  0.4265, -0.2308, -0.2280,\n",
       "         0.2760, -0.3640, -0.0778, -0.0845, -0.0731,  0.1622, -0.4413,  0.3059,\n",
       "        -0.0881, -0.0130,  0.0757, -0.2332,  0.4442, -0.0942,  0.5552, -0.1509,\n",
       "        -0.1043, -0.1948,  0.5478,  0.0859, -0.2478, -0.0625,  0.3247,  0.2996,\n",
       "        -0.2435, -0.4102,  0.0578,  0.3489, -0.7164,  0.2303,  0.1944, -0.2771,\n",
       "         0.2100, -0.1262,  0.1068,  0.0214,  0.3504, -0.1311,  0.1748, -0.2691,\n",
       "         0.0029,  0.0104, -0.3292,  0.1996, -0.3375,  0.0717, -0.2664, -0.4196,\n",
       "         0.6413, -0.0685, -0.1927,  0.0389,  0.0931, -0.3176,  0.2523, -0.3976,\n",
       "         0.1326,  0.0711,  0.2238,  0.1500,  0.4241,  0.1957, -0.2176,  0.0268,\n",
       "         0.1342,  0.3147,  0.3435,  0.0103,  0.1182,  0.4516, -0.3697, -0.1329,\n",
       "        -0.3553, -0.1703, -0.0199, -0.1042,  0.2690,  0.4170,  0.3875,  0.0943,\n",
       "        -0.0835, -0.2307, -0.2256, -0.0795,  0.1158,  0.2564,  0.0741,  0.3811,\n",
       "         0.1703, -0.3204,  0.4812, -0.0035,  0.3751, -0.3273, -0.2228,  0.2750,\n",
       "         0.0316, -0.2051,  0.2077,  0.2139,  0.0414, -0.3371, -0.1677,  0.1480,\n",
       "         0.1252,  0.1552, -0.4561, -0.1814, -0.1710,  0.2203,  0.1713, -0.0138,\n",
       "         0.2858,  0.0078, -0.2655,  0.0479, -0.3545, -0.2006, -0.2876, -0.1575,\n",
       "         0.2398,  0.1443,  0.0343, -0.0671, -0.0084, -0.7234, -0.2806,  0.2888,\n",
       "        -0.1060,  0.3282, -0.3410,  0.0465, -0.2637, -0.0039, -0.6280, -0.2599,\n",
       "        -0.2146,  0.3256, -0.1583, -0.0263, -0.1490,  0.0385, -0.1126,  0.2180,\n",
       "         0.2132,  0.2123, -0.1494,  0.3209,  0.4704, -0.0305, -0.3234,  0.3352,\n",
       "        -0.1090,  0.4929,  0.2667,  0.3061,  0.7609,  0.1353, -0.5023, -0.2341,\n",
       "        -0.3978, -0.1520, -0.0465, -0.2159,  0.0190,  0.4953,  0.1825,  0.2171,\n",
       "         0.4937,  0.3138, -0.2316,  0.0553,  0.0698,  0.1001, -0.0879, -0.1324,\n",
       "         0.2774,  0.1675, -0.5551, -0.0478, -0.1741, -0.1687,  0.0897,  0.5281,\n",
       "        -0.1122, -0.5845,  0.2788, -0.2621])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.vectors[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.建构模型：Input Encoding ; Local Inference Modeling ; Inference Composition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Input Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如论文所述，对于ESLM而言，Input Encoding是一个双向的LSTM模型，分别计算premise、hypothesis的所有隐藏状态，然后将他们在每个时间步拼接起来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputEncodingLayer(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size):\n",
    "        super(InputEncodingLayer,self).__init__()\n",
    "        self.lstm=nn.LSTM(input_size,hidden_size,num_layers=1,bidirectional=True)\n",
    "    def forward(self,X):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            X:{torch.Tensor}--输入 embedding shape[batch_size,seq_len,input_size]\n",
    "        Return:\n",
    "            output{torch.Tensor}--shape[batch_size,seq_len,num_directions*hidden_size]\n",
    "\n",
    "        \"\"\"\n",
    "        #self.lstm.flatten_parameters()\n",
    "        output,_=self.lstm(X) #output,(h,c)这里只要由hiddenstate构成的output，不需要h和c\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Local Inference Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "打分函数是点积模型，对打分进行softmax得到注意力分布，以一组文本的一个词向量为query，求另一组文本的所有注意力分布，然后求加权和，最后将hiddenstate，加权和，两者之差，两者点乘进行连接输入到下一层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalInference(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LocalInference,self).__init__()\n",
    "        self.softmax_1=nn.Softmax(dim=1)\n",
    "        self.softmax_2=nn.Softmax(dim=2)\n",
    "        #dim=1则是除了batch外的一个二维矩阵，第一维之和为1,dim=2同理\n",
    "        \n",
    "    def forward(self,p,h,p_mask,h_mask):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            前一个inputencoding层的输出\n",
    "            p {torch.Tensor} -- p has shape [batch, seq_len_p, 2 * hidden_size]\n",
    "            h {torch.Tensor} -- h has shape [batch, seq_len_h, 2 * hidden_size]\n",
    "           \n",
    "            p_mask {torch.Tensor (int)} -- p has shape [batch, seq_len_p], 0 in the mask\n",
    "                means padding.\n",
    "            h_mask {torch.Tensor (int)} -- h has shape [batch, seq_len_h]\n",
    "        Returns:\n",
    "            将p,p_,p-p_,p*p_在最后一维上连接起来\n",
    "            m_p, m_h {torch.Tensor} -- tensor with shape [batch, seq_len, 8 * hidden_size]\n",
    "        \"\"\"\n",
    "        # equation 11,获得注意分布矩阵\n",
    "        e=torch.matmul(p,h.transpose(1,2))\n",
    "        \"\"\"\n",
    "        用的是点积打分模型，直接相乘然后softmax就是注意力分布，总的分布矩阵[batch,seq_len_p,seq_len_h]\n",
    "        这个矩阵横着看每一行代表以premise的一个词向量为query查询的注意力分布                         \n",
    "        纵向看每一列代表以hypothesis的一个词向量维query查询的注意力的分布\n",
    "        [[e11 e12 e13 e1h]\n",
    "         [e21 e22 e23 e2h]\n",
    "         [e31 e32 e33 e3h]\n",
    "         [ep1 ep2 ep3 eph]]\n",
    "        \"\"\"\n",
    "        \n",
    "        #获取掩码矩阵\n",
    "        inference_mask=torch.matmul(p_mask.unsqueeze(2).float(),h_mask.unsqueeze(1).float()) #[batch,seq_len_p,seq_len_h]\n",
    "        #这个矩阵同上面的注意力分布矩阵相同，横看每一行是hypothesis的mask，纵向每一列是premise的mask\n",
    "       \n",
    "        assert inference_mask.shape==e.shape\n",
    "        # masking the scores for padding tokends\n",
    "        e.masked_fill_(inference_mask<1e-7,-1e7)\n",
    "        \n",
    "        #equation 12,13\n",
    "        h_score,p_score=self.softmax_1(e),self.softmax_2(e) \n",
    "        h_=h_score.transpose(1,2).bmm(p) #按照输出[batch,seq_len_h,2*hidden_size]对参与运算的矩阵进行转置满足即可\n",
    "        p_=p_score.bmm(h)               #[batch,seq_len_p,2*hidden_size]\n",
    "        \"\"\"\n",
    "        p_对应论文中的a~，是ei1 ei2 ei3 ei4这样的方向(横向)做softmax，也就是在seq_len_h维度上和为1，对应softmax的dim=2\n",
    "        h_对应论文中的b~，是e1j e2j e3j e4j这样的方向(纵向)做softmax，也就是在seq_len_p维度上和为1，对应softmax的dim=1\n",
    "        \"\"\"\n",
    "        \n",
    "        assert p.shape==p_.shape and h.shape==h_.shape\n",
    "        \n",
    "        #equation 14,15\n",
    "        m_p=torch.cat((p,p_,p-p_,p*p_),dim=-1) #按照最后一个维度将4个向量拼接起来\n",
    "        m_h=torch.cat((h,h_,h-h_,h*h_),dim=-1)\n",
    "        assert m_p.shape[-1]==p.shape[-1]*4\n",
    "        \n",
    "        return m_p,m_h\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.,  2.,  3.],\n",
      "         [ 4.,  5.,  6.,  7.]],\n",
      "\n",
      "        [[ 8.,  9., 10., 11.],\n",
      "         [12., 13., 14., 15.]]]) \n",
      " tensor([[[0.0180, 0.0180, 0.0180, 0.0180],\n",
      "         [0.9820, 0.9820, 0.9820, 0.9820]],\n",
      "\n",
      "        [[0.0180, 0.0180, 0.0180, 0.0180],\n",
      "         [0.9820, 0.9820, 0.9820, 0.9820]]]) \n",
      " tensor([[[0.0321, 0.0871, 0.2369, 0.6439],\n",
      "         [0.0321, 0.0871, 0.2369, 0.6439]],\n",
      "\n",
      "        [[0.0321, 0.0871, 0.2369, 0.6439],\n",
      "         [0.0321, 0.0871, 0.2369, 0.6439]]])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"测试softmax维度\"\"\"\n",
    "x=torch.tensor((range(16)),dtype=torch.float32).view(2,2,4)\n",
    "x\n",
    "s1=nn.Softmax(dim=1)\n",
    "s2=nn.Softmax(dim=2)\n",
    "print(x,'\\n',s1(x),'\\n',s2(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Inference Composition：包含compostionlayer和poolinglayer、MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### compositionlayer：继续使用BiLSTM，aims to capture local inference imformation ma and mb and their context for inference  compostion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompositionLayer(nn.Module):\n",
    "    def __init__(self,input_size,output_size,hidden_size):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            input_size{int}-- 前馈网络输入向量尺寸\n",
    "            output_size{int}--前馈网络输出向量尺寸，同时也是LSTM输入向量\n",
    "            hidden_size{int}--LSTM隐藏状态的向量尺寸\n",
    "        \n",
    "        \"\"\"\n",
    "        super(CompositionLayer,self).__init__()\n",
    "        self.hidden_size=hidden_size\n",
    "        self.F=nn.Linear(input_size,output_size)\n",
    "        self.lstm=nn.LSTM(input_size=output_size,hidden_size=hidden_size,num_layers=1,bidirectional=True)\n",
    "        self.dropout=nn.Dropout(0.5) #前馈网络输出进过dropout层\n",
    "    def forward(self,m):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            m{torch.tensor}--{batch,seq_len,input_size}\n",
    "        Returns:\n",
    "            outputs{torch.tensor}--{batch,seq_len,hidden_size*2}\n",
    "        \"\"\"\n",
    "        y=self.dropout(self.F(m))\n",
    "        #self.lstm.fatten_parameters()\n",
    "        outputs,_=self.lstm(y)\n",
    "        return outputs\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pooling：将之前得到的向量通过池化转换成固定长度的向量并输入的最后的分类器，同时采用平均池化和最大池化然后拼接起来成固定长度的向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Pooling,self).__init__()\n",
    "        \n",
    "    def forward(self,x,x_mask):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x {torch.tensor} --[batch,seq_len,hidden_size*2]\n",
    "            x_mask{torch.tensor}--[batch,seq_len] padding位置值为0\n",
    "        Returns:\n",
    "            V{torch.tensor}--[batch,hidden_size*4]\n",
    "        \"\"\"\n",
    "        mask_expand=x_mask.unsqueeze(-1).expand(x.shape) #首先扩展x_mask的第三维，此时只是单纯的改变视图，并没有添加新的值\n",
    "                                                        #，然后将用expand方法将mask的维度扩展到与x的形状相同，expand方法填充是复制\n",
    "        #平均池化\n",
    "        \"\"\"\n",
    "        首先与掩码矩阵进行点积，然后求每个batch的总的非填充向量数，sum(-1)后的形状是[batch]，要对每个样本分别求平均，就要把维度扩展为[batch,1]\n",
    "        x.sum(1)后形状为[batch,hidden_size*2]\n",
    "        \"\"\"\n",
    "        x_=x*mask_expand.float()\n",
    "        v_avg=x_.sum(1)/x_mask.sum(-1).unsqueeze(-1).float() \n",
    "      \n",
    "        \n",
    "        #最大池化层\n",
    "        x_=x.masked_fill(mask_expand==0,-1e7)\n",
    "        v_max=x_.max(1).values #max(1)在dim=1上求最大，然后这个维度消失。返回一个类，其values属性是torch.tensor，[batch,hidden_size*2]\n",
    "        \n",
    "        return torch.cat((v_avg,v_max),dim=1) #[batch,hidden_size*4]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.1157, 0.4712, 0.1455],\n",
       "          [0.9834, 0.9600, 0.6661]],\n",
       " \n",
       "         [[0.3223, 0.4334, 0.1320],\n",
       "          [0.2990, 0.7387, 0.6437]],\n",
       " \n",
       "         [[0.9825, 0.0839, 0.9926],\n",
       "          [0.0182, 0.7709, 0.3424]],\n",
       " \n",
       "         [[0.9994, 0.8482, 0.0176],\n",
       "          [0.2477, 0.0134, 0.6837]]]),\n",
       " tensor([[1.0991, 1.4312, 0.8116],\n",
       "         [0.6213, 1.1721, 0.7757],\n",
       "         [1.0007, 0.8548, 1.3350],\n",
       "         [1.2471, 0.8616, 0.7013]]),\n",
       " torch.Size([4, 3]),\n",
       " tensor([[0.7324, 2.6095],\n",
       "         [0.8877, 1.6815],\n",
       "         [2.0590, 1.1315],\n",
       "         [1.8652, 0.9448]]),\n",
       " tensor([[0.9834, 0.9600, 0.6661],\n",
       "         [0.3223, 0.7387, 0.6437],\n",
       "         [0.9825, 0.7709, 0.9926],\n",
       "         [0.9994, 0.8482, 0.6837]]))"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.rand((4,2,3),dtype=torch.float32)\n",
    "x,x.sum(1),x.sum(1).shape,x.sum(-1),x.max(1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### InferenceComposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceComposition(nn.Module):\n",
    "    def __init__(self,input_size,output_size,hidden_size):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            input_size{int}-- 前馈网络输入向量尺寸\n",
    "            output_size{int}--前馈网络输出向量尺寸，同时也是LSTM输入向量\n",
    "            hidden_size{int}--LSTM隐藏状态的向量尺寸\n",
    "        \"\"\"\n",
    "        super(InferenceComposition,self).__init__()\n",
    "        self.composition=CompositionLayer(input_size,output_size,hidden_size)\n",
    "        self.pooling=Pooling()\n",
    "    def forward(self,m_p,m_h,p_mask,h_mask):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            m_p {torch.Tensor} -- [batch, seq_len, input_size]\n",
    "            m_h {torch.Tensor} -- [batch, seq_len, input_size]\n",
    "            mask {torch.Tensor} -- [batch, seq_len], 0 means padding\n",
    "        Returns:\n",
    "            v {torch.Tensor} -- [batch, hidden_size * 8]        --对应论文公式20\n",
    "        \n",
    "        \"\"\"\n",
    "        v_p,v_h=self.composition(m_p),self.composition(m_h)\n",
    "        v_p_,v_h_=self.pooling(v_p,p_mask),self.pooling(v_h,h_mask) #[batch,hidden_size*4]\n",
    "        v=torch.cat((v_p_,v_h_),dim=1)\n",
    "        \n",
    "        return v\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multilayer perceptron classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self,input_size,output_size,class_num):\n",
    "        super(MLP,self).__init__()\n",
    "        self.activation=nn.ReLU()\n",
    "        self.dropout=nn.Dropout(0.5)\n",
    "        self.mlp=nn.Sequential(self.dropout,nn.Linear(input_size,output_size),self.activation,nn.Linear(output_size,class_num))\n",
    "    def forward(self,X):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x {torch.Tensor} -- [batch, features]\n",
    "        Returns:\n",
    "            logits {torch.Tensor} -- raw, unnormalized scores for each class. [batch, class_num]\n",
    "        \"\"\"\n",
    "        logits=self.mlp(X)\n",
    "        return logits\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.ESIM模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESIM(nn.Module):\n",
    "   \n",
    "    def __init__(self,hidden_size,embedding_dim,vocab_size,num_labels,device):\n",
    "   \n",
    "        \"\"\"\n",
    "            Arguments:\n",
    "            hidden_size{int} -- LSTM隐藏层的向量尺寸\n",
    "            vocab_size{int} -- 字典中的单词数\n",
    "            embedding_dim{int}-- 词向量的维度\n",
    "            num_labels{int}--分类数\n",
    "        \"\"\"\n",
    "        super(ESIM,self).__init__()\n",
    "        self.device=device\n",
    "        self.embedding=nn.Embedding(vocab_size,embedding_dim)\n",
    "        self.encoder=InputEncodingLayer(embedding_dim,hidden_size)\n",
    "        self.inference=LocalInference()\n",
    "        self.infercomposition=InferenceComposition(hidden_size*8,hidden_size,hidden_size)\n",
    "        self.linear=MLP(hidden_size*8,hidden_size,num_labels)\n",
    "    \n",
    "    def forward(self,p,h):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "                p {torch.Tensor} -- premise [batch, seq_len]\n",
    "                h {torch.Tensor} -- hypothesis [batch, seq_len]\n",
    "            Returns:\n",
    "                logits {torch.Tensor} -- raw, unnormalized scores for each class\n",
    "                    with shape [batch, class_num]\n",
    "        \"\"\"\n",
    "        p_embedding=self.embedding(p)\n",
    "        h_embedding=self.embedding(h)\n",
    "        p_=self.encoder(p_embedding)\n",
    "        h_=self.encoder(h_embedding)\n",
    "    \n",
    "        p_mask,h_mask=(p!=1).long(),(h!=1).long()\n",
    "        m_p,m_h=self.inference(p_,h_,p_mask,h_mask)\n",
    "    \n",
    "        v=self.infercomposition(m_p,m_h,p_mask,h_mask)\n",
    "            \n",
    "        logits=self.linear(v)\n",
    "    \n",
    "        return logits\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size,embedding_dim,num_labels=300,300,3\n",
    "net=ESIM(hidden_size,embedding_dim,len(vocab),num_labels,device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载预训练的词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0438,  0.0248, -0.2094,  ..., -0.3010, -0.1458,  0.2819],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.embedding.weight.data.copy_(vocab.vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net, device=None):\n",
    "    if device is None and isinstance(net, torch.nn.Module):\n",
    "        # 如果没指定device就使用net的device\n",
    "        device = list(net.parameters())[0].device \n",
    "    acc_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_iter):\n",
    "            premise=batch.premise[0]\n",
    "            hypothesis=batch.hypothesis[0]\n",
    "            y=batch.label\n",
    "            premise=premise.to(device)\n",
    "            hypothesis=hypothesis.to(device)\n",
    "            y=y.to(device)\n",
    "            if isinstance(net, torch.nn.Module):\n",
    "                net.eval() # 评估模式, 这会关闭dropout\n",
    "                acc_sum += (net(premise,hypothesis).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n",
    "                net.train() # 改回训练模式\n",
    "            else: # 自定义的模型\n",
    "                if('is_training' in net.__code__.co_varnames): # 如果有is_training这个参数\n",
    "                    # 将is_training设置成False\n",
    "                    acc_sum += (net(premise,hypothesis, is_training=False).argmax(dim=1) == y).float().sum().item() \n",
    "                else:\n",
    "                    acc_sum += (net(premise,hypothesis).argmax(dim=1) == y).float().sum().item() \n",
    "            n += y.shape[0]\n",
    "    return acc_sum / n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_iter,test_iter,net,loss,optimizer,device,num_epochs):\n",
    "    net=net.to(device)\n",
    "    print(\"training on \",device)\n",
    "    batch_count=0\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum,train_acc_sum,n,start=0.0,0.0,0,time.time()\n",
    "        for batch in tqdm(train_iter):\n",
    "            premise=batch.premise[0]\n",
    "            hypothesis=batch.hypothesis[0]\n",
    "            y=batch.label\n",
    "            #print(y)\n",
    "            premise=premise.to(device)\n",
    "            hypothesis=hypothesis.to(device)\n",
    "            y=y.to(device)\n",
    "            y_hat=net(premise,hypothesis)\n",
    "            #print(y_hat.shape,y.shape)\n",
    "            l=loss(y_hat,y)\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            train_l_sum+=l.cpu().sum().item()\n",
    "            train_acc_sum+=(y_hat.argmax(dim=1)==y).sum().cpu().item()\n",
    "            n+=y.shape[0]\n",
    "            batch_count+=1\n",
    "        test_acc=evaluate_accuracy(test_iter,net)\n",
    "        print(\"epoch %d,loss %.4f, train acc %.3f, test acc%.3f ,time%.1f sec\"%\n",
    "              (epoch+1,train_l_sum,train_acc_sum/n,test_acc,time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                        | 0/17168 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 17168/17168 [23:54<00:00, 11.97it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 307/307 [00:05<00:00, 53.97it/s]\n",
      "  0%|                                                                                        | 0/17168 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1,loss 8656.3210, train acc 0.803, test acc0.827 ,time1440.3 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 17168/17168 [25:00<00:00, 11.44it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 307/307 [00:05<00:00, 56.03it/s]\n",
      "  0%|                                                                                        | 0/17168 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2,loss 7751.3534, train acc 0.828, test acc0.831 ,time1505.9 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 17168/17168 [24:45<00:00, 11.56it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 307/307 [00:05<00:00, 54.82it/s]\n",
      "  0%|                                                                                        | 0/17168 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3,loss 7429.7429, train acc 0.837, test acc0.834 ,time1491.2 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 17168/17168 [24:17<00:00, 11.78it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 307/307 [00:05<00:00, 55.54it/s]\n",
      "  0%|                                                                                        | 0/17168 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4,loss 7254.6632, train acc 0.841, test acc0.831 ,time1463.2 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 17168/17168 [24:18<00:00, 11.77it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 307/307 [00:05<00:00, 56.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5,loss 7158.3898, train acc 0.843, test acc0.831 ,time1463.5 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "lr,num_epochs=0.001,5\n",
    "#过滤掉embedding参数，因为其不计算梯度不更新\n",
    "optimizer=torch.optim.Adam(filter(lambda p:p.requires_grad,net.parameters()),lr=lr)\n",
    "loss=nn.CrossEntropyLoss()\n",
    "train(train_iter,test_iter,net,loss,optimizer,device,num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从训练效果来看，LOSS在稳步下降，训练集的准确率也在稳定上升，猜想随着训练次数的增加，准确率会进一步的升高，但是由于计算硬件的限制，我的每个epoch训练时间太长了，基本都在22分钟左右，所以没有做进一步的测试，总的来说得到的参数较好，准确率达到了百分之83左右，比较理想，同时由于硬件条件的限制，并没有使用dev_iter来进行模型的选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
